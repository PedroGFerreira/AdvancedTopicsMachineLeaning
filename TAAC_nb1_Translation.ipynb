{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcn+InG7KlgU4BAWcKf03b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroGFerreira/AdvancedTopicsMachineLeaning/blob/main/TAAC_nb1_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translating text from Portuguese to English\n",
        "We will test two approaches to use an LLM for text translation.\n",
        "\n",
        "\n",
        "1.   Using a Pre-trained and open-source model\n",
        "2.   Using API to Access a commercial LLM\n",
        "\n",
        "For 1) we will HuggingFace that provides the Transformers library and access to different models.  The Transformers will be explored in more detail in a subsequent notebook.\n",
        "The model will be the unicamp-dl/translation-pt-en-t5:\n",
        "[link text](https://huggingface.co/unicamp-dl/translation-pt-en-t5)\n",
        "\n",
        "This is an implementation of T5 for translation in PT-EN tasks using a modest hardware setup.\n",
        "\n",
        "**Note that models regarding the portuguese language are not so frequent. **\n",
        "\n",
        "At HuggingFace there is at least another PT to EN translator from Unbabel. But this is a much larger model with 13B parameters that is trained to perform other tasks besides translation: [link text](https://huggingface.co/Unbabel/TowerInstruct-13B-v0.1)\n",
        "\n",
        "\n",
        "For 2) we will use the chtGPT version3.5-turbo. To access this program programatically via an API you will need to have API key. You should register at the openAI website and generate an API Key. Your scriptin environment should be set to this Key.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UTYv8EqCyJkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all the necessaries packages\n",
        "# creating a virtual environment in your project directory\n",
        "!python -m venv .env\n",
        "# Activate the virtual environment\n",
        "!source .env/bin/activate\n",
        "# ready to install ü§ó Transformers with the following command:\n",
        "!pip install transformers\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "d6zm4_gDDL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load here the packages for the remainder of the script\n",
        "import os\n",
        "import openai\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
      ],
      "metadata": {
        "id": "LTledArIxrxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WBXPQKL_x2eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Pre-trained and Open-Source Translation Model\n",
        "\n",
        "Here we use to approached to accomplish the translation task. A more direct approach is using the *pipeline* functionality from the Transformers package.\n",
        "\n",
        "A second approach is to use the functionality apply_chat_template that is used to create an interactive chating approach. This may not be the most adequate approach since the translation model used here is more adequate for direct translations. Nevertheless, the chat-based template is used for demonstration. See more here:\n",
        "[link text](https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        ")"
      ],
      "metadata": {
        "id": "qjU07NL10p1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Initialize the translation pipeline using a model trained for Portuguese to English translation\n",
        "pten_pipeline = pipeline('text2text-generation', model=\"unicamp-dl/translation-pt-en-t5\")\n",
        "\n",
        "# portuguese text to translate\n",
        "portuguese_text = \"Bem vindo ao curso de T√≥picos Avan√ßados de Aprendizagem Autom√°tica\"\n",
        "\n",
        "# 1 - Using directly the pipeline function from Hugging Face\n",
        "text_to_translate = \"translate Portuguese to English: %s\" % portuguese_text\n",
        "translated_text = pten_pipeline(text_to_translate)[0]['generated_text']\n",
        "print(\"Translated Text:\", translated_text)\n",
        "\n",
        "# 2- Chat Template\n",
        "# The apply_chat_template is a method in Huggingface's tokenizers library that can be used to format messages in a chat-like context.\n",
        "# This method is often used with models that are designed for chat-based interactions.\n",
        "# using the apply_chat_template with a translation model such as those in the AutoModelForSeq2SeqLM family isn't standard, since these models aren't usually designed for chat-style inputs.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
        "\n",
        "# Apply chat template (conceptual example)\n",
        "formatted_input = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a translator. Translate the following text from Portuguese to English.\"},\n",
        "        {\"role\": \"user\", \"content\": portuguese_text}\n",
        "    ],\n",
        "    roles=[\"system\", \"user\"],\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Generate the translation\n",
        "generated_tokens = model.generate(\n",
        "    formatted_input,\n",
        "    max_length=200,  # Adjust based on the expected length of the output\n",
        ")\n",
        "\n",
        "# Decode the generated tokens to get the translated text\n",
        "translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the translated text\n",
        "# Note that the text contains the identifiers that are used as control tokens.\n",
        "print(\"Translated Text:\", translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZedUhnaGpZZ",
        "outputId": "5de7a1d5-b881-45ff-bf4f-f513cb943252"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Text: <|im_end|> <|im_start|>user Welcome to the Course of Advanced Topics of Automatic Learning<|im_end|> <|im_start|>system You are a translator. Translate the following text from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using an API to a Commercial Model\n",
        "\n",
        "Here you need to start by setting the API KEY. In this case, as I was using colab, my Keys are stored in the \"Secrets\" section. In alternative the key can be hard coded in the text as:\n",
        "\n",
        "```\n",
        "openai.api_key = \"........\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FQi21n4sHpyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your OpenAI API key\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Define the Portuguese text to be translated\n",
        "portuguese_text = \"Bem vindo ao curso de T√≥picos Avan√ßados de Aprendizagem Autom√°tica\"\n",
        "\n",
        "# Use the OpenAI Chat API to translate the text\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # You can also use \"gpt-4\" if available\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates Portuguese to English.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Translate the following Portuguese text to English: {portuguese_text}\"}\n",
        "    ],\n",
        "    temperature=0.0,  # Lower temperature for more deterministic output\n",
        ")\n",
        "\n",
        "# Extract the translated text\n",
        "translated_text = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Print the translated text\n",
        "print(\"Translated Text:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNCC9USuHwHM",
        "outputId": "8eb46aeb-7ef3-442d-be7d-f8f0863d0941"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Text: Welcome to the Advanced Topics in Machine Learning course.\n"
          ]
        }
      ]
    }
  ]
}